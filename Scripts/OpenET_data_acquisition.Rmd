---
title: "OpenET Data Acquisition"
author: "Carrie Hashimoto"
version: "2024-08-06"

output:
  pdf_document:
    theme: lumen
    df_print: paged
---
# source: https://github.com/codeswitching/OpenET-API-with-R-tutorial/blob/main/README.md
- edited
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(comment = NA)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

```{r, warning = FALSE, message = FALSE}

packages <- c('terra','jsonlite','sp','httr',
              'rasterVis','ggplot2','magrittr','RColorBrewer','xml2','dygraphs',
              'xts','lubridate','DT','rmarkdown', 'rprojroot','imager','htmltools',
              "raster","ggplot2","rasterVis","tmap")

new.packages = packages[!(packages %in% installed.packages()[,"Package"])]

# Install new (not installed) packages
if(length(new.packages)) install.packages(new.packages, repos='http://cran.rstudio.com/') else print('All required packages are installed.')

invisible(lapply(packages, library, character.only = TRUE))
```

```{r}
# Create an output directory if it doesn't exist
wd <- rprojroot::find_rstudio_root_file()
outDir <- file.path(wd, "Data", "R_Output", fsep="/")
suppressWarnings(dir.create(outDir)) 

httr::set_config(httr::config(ssl_verifypeer=0L))
```

```{r}
getOpenET <- function (date_range, model,variable, reference_et, units,
                       geometry,interval,url_text, api_key) 
  
  # inputs
  ## date_range: c('yyy-mm-dd','yyyy-mm-dd')
  ## model: format str
  ## variable
  ## reference_et
  ## units: "mm", "in"
  ## geometry: format c(xmin, ymax, xmin, ymin, xmax, ymin, xmax, ymax)
  ## interval: "monthly
  ## url_text: format str, "https://openet-api.org/raster/geotiff/stack"
  ## api_key: format str
  
  # outputs
  ## response_url: url as str
  {
  response <- GET(url_text, add_headers(accept = "application/json", Authorization = api_key),
                  query = list(date_range         = date_range,
                               model              = model, # ensemble, eemetric, ssebop, geesebal, sims, disalexi, ptjpl
                               variable           = variable,           # et, ndvi, etof, eto, pr
                               reference_et       = reference_et,      # cimis, gridmet
                               units              = units,              # metric, english
                               geometry           = geometry,           # polygon coordinates
                               interval           = interval))           # monthly, daily
  
                               # below attributes don't seem to be in the list needed for geotiff stack
                               # include_columns    = include_columns,    # shapefile attributes to include in the csv
                               # filename_suffix    = filename_suffix))   # name to append to file
  
  if (http_error(response)) {                     # if the server returned an error
    cat('The API server returned an error:\n')
    cat(http_status(response)$message) }
  else {                                         # if successful
    cat(content(response)$status)
    response_url <- content(response)$bucket_url  # read the url for the requested data
    cat('When ready, requested data can be accessed at this url:\n')
    cat(response_url)
    }
  
  return(response_url) # return the url for the requested data (may take minutes or hours)
}
```

```{r}
# set working directory
wd <- rprojroot::find_rstudio_root_file()
outDir <- file.path(wd, "Data", "R_Output", fsep="/")
suppressWarnings(dir.create(outDir)) 

# Load the GeoJSON file and extract the boundary
boundary_vect <- terra::vect("Data/CreekFire_1km_buffer.geojson")

# Choose number of boxes along each edge
x_boxes <- 3 # if using an account not connected to EE, need to have more bc
y_boxes <- 3 # you can query less area per request

# note: add automation later to determine number of boxes needed

# create a grid of points over the boundary extent
xvals <- seq(terra::ext(boundary_vect)[1], terra::ext(boundary_vect)[2], length.out = x_boxes+1)
yvals <- seq(terra::ext(boundary_vect)[3], terra::ext(boundary_vect)[4], length.out = y_boxes+1)

# function to format box coordinates
make_box <- function(xmin,xmax,ymin,ymax) {
  # use ordering appropriate for OpenET
  # topleft, bottomleft, bottomright, topright (I think?)
  return(c(xmin,ymax,xmin,ymin,xmax,ymin,xmax,ymax))
}

# make a list of boxes and add all the boxes to it, using make_box to format
boxes <- list()
for (i in 1:x_boxes){
  for (j in 1:y_boxes){
    boxes[[i+x_boxes*(j-1)]] <- make_box(xvals[i],xvals[i+1],yvals[j],yvals[j+1])
  }
}

# some boxes within the bounding box are totally outside the burn area
# choose the boxes you want by hand - figure out how to automate later
names(boxes) <- 1:length(boxes)

# can manually define selected boxes or just get all
selected_boxes <- boxes

# take a look at the boxes you selected to make sure you're requesting the right data
plot(terra::ext(boundary_vect))
lines(boundary_vect)
for (i in 1:length(selected_boxes)){
  polygon(x=selected_boxes[[i]][c(1,3,5,7)],y=selected_boxes[[i]][c(2,4,6,8)])
  text(x=(selected_boxes[[i]][1]+selected_boxes[[i]][5])/2,y=(selected_boxes[[i]][2]+selected_boxes[[i]][4])/2,labels=names(selected_boxes)[i])
}

```

Download zips and open them to make tifs:
```{r}
make_JSON <- function(date_range = c('2020-01-01', '2020-12-31'), model = 'ensemble',
                      variable = c('et','ndvi'), reference_et = 'cimis', units = 'english',
                      geometry = c(-119.7937, 35.58995, -119.7937, 35.53326, -119.71268, 35.53326, -119.71268, 35.58995),
                      interval = 'monthly') {
  # inputs
  ## date_range: c('YYYY-MM-DD','YYYY-MM-DD')
  ## model: str
  ## variable: str or vec of strs
  ## reference_et: str
  ## units: str
  ## geometry: double vec, c(xmin, ymax, xmin, ymin, xmax, ymin, xmax, ymax)
  ## interval: str
  
  # outputs: none
  
  toJSON(list(
    date_range = date_range,
    geometry = geometry,
    interval = interval,
    model = model,
    reference_et = reference_et,
    units = units,
    variable = variable
  ), auto_unbox = TRUE)
}


# define the URL and API key
url_text <- "https://openet-api.org/raster/geotiff/stack"
api_key <- "paste API key here"

# define date range
date_ranges <- list(c('2020-06-01', '2020-08-31'),
                    c('2021-06-01', '2021-08-31'))


```



```{r}
i <- 8
j <- 2


for (i in 1:length(date_ranges)){
  for (j in 1:length(selected_boxes)) {
    payload <- make_JSON(
    date_range = date_ranges[[j]],
    geometry = selected_boxes[[i]],
    interval = "monthly",
    model = "ensemble",
    reference_et = "gridMET",
    units = "mm",
      variable = "ET")

    # print the payload for verification
    cat("payload:",payload)

    # Make the POST request
    response <- POST(
      url = url_text,
      add_headers(
        accept = "application/json",
        `Content-Type` = "application/json",
        Authorization = api_key
      ),
      body = payload,
      encode = "json"
    )

    # print the response content and status code
    cat("box:", names(selected_boxes)[[i]], ", date_range:", date_ranges[[j]], "status_code:",print(status_code(response),sep=""))

    response_urls <- content(response, "parsed") # I'm not totally sure what this line does...

    # download the zips
    for (k in 1:length(response_urls)) {

      # create an output directory if it doesn't exist
      wd <- rprojroot::find_rstudio_root_file()
      
      # save both the zips and the tifs to be safe
      zip_dir <- file.path(wd, "Data/openET_data/zips", paste0("corner",names(selected_boxes)[[i]]), fsep="/")
      tif_dir <- file.path(wd, "Data/openET_data/tiffs", paste0("corner",names(selected_boxes)[[i]]), fsep="/")
      box_response_name <- paste0("box",names(selected_boxes)[[i]],"_",names(response_urls)[k])
      suppressWarnings(dir.create(zip_dir))
  
      download.file(as.character(response_urls[k]),
                  destfile=paste0(zip_dir,"/",box_response_name,".zip"),
                  method = "curl")
      
      unzip(paste0(zip_dir,"/",box_response_name,".zip"),
          exdir = tif_dir)
      
      file.rename(from=paste0(tif_dir,"/ensemble_et_",names(response_urls)[k],".tif"),
                to=paste0(tif_dir,"/",box_response_name,".tif"))
    }
    
    cat("box", names(selected_boxes)[[i]], "dates", date_ranges[[j]], "completed.")
  }
}



```

For corner sub-boxes:
```{r}
i <- 9
j <- 2

# Check the geometry you're querying
plot(boundary_vect)
polygon(sub_boxes[[i]][c(1,3,5,7)],sub_boxes[[i]][c(2,4,6,8)])

payload <- make_JSON(
  date_range = date_ranges[[j]],
  geometry = sub_boxes[[i]],
  interval = "monthly",
  model = "ensemble",
  reference_et = "gridMET",
  units = "mm",
    variable = "ET")

# Print the payload for verification
print(payload)

# Make the POST request
response <- POST(
url = url_text,
add_headers(
  accept = "application/json",
  `Content-Type` = "application/json",
  Authorization = api_key
),
body = payload,
encode = "json"
)

# Print the response content and status code
cat("box:", names(sub_boxes)[[i]], ", date_range:", date_ranges[[j]], "status_code:",print(status_code(response),sep=""))

response_urls <- content(response, "parsed")

# download the zips
for (k in 1:length(response_urls)) {

  # Create an output directory if it doesn't exist
  wd <- rprojroot::find_rstudio_root_file()
  zip_dir <- file.path(wd, "Data/openET_data/zips", paste0("corner",names(sub_boxes)[[i]]), fsep="/")
  tif_dir <- file.path(wd, "Data/openET_data/tiffs", paste0("corner",names(sub_boxes)[[i]]), fsep="/")
  box_response_name <- paste0("box",names(sub_boxes)[[i]],"_",names(response_urls)[k])
  suppressWarnings(dir.create(zip_dir))
  suppressWarnings(dir.create(tif_dir))

  download.file(as.character(response_urls[k]),
                destfile=paste0(zip_dir,"/",box_response_name,".zip"),
                method = "curl")
  unzip(paste0(zip_dir,"/",box_response_name,".zip"),
        exdir = tif_dir)
  file.rename(from=paste0(tif_dir,"/ensemble_et_",names(response_urls)[k],".tif"),
              to=paste0(tif_dir,"/",box_response_name,".tif"))
  }
cat("box", names(sub_boxes)[[i]], "dates", date_ranges[[j]], "completed.")


```

Create stack from existing files:
```{r}
saved_boxes <- list.files(paste0(wd,"Data/openET_data/tiffs"))

for (i in 1:length(saved_boxes)){
  
  # get all files in box i directory that are for individual dates
  dir_str <- paste0("Data/openET_data/tiffs/",saved_boxes[i])
  dir_contents <- list.files(dir_str)
  match_name <- grepl(pattern=".+_[0-9]{4}-[0-9]{2}-[0-9]{2}.tif",x=dir_contents)

  # initialize stack
  et_stack <- list()
  # add all ET date tifs into stack
  for (j in 1:length(dir_contents[match_name])) {
    file_str <- paste0(dir_str,"/",dir_contents[j])
    et_layer <- terra::rast(file_str)
    # exclude infs
    et_layer[!is.finite(values(et_layer))] <- NA # might need to confirm this method works
    et_stack[[j]] <- et_layer
    rm(et_layer) # don't clutter up working memory
  }
  
  # put the stack into one raster
  et_stack <- terra::rast(et_stack)
  output_name <- file.path(dir_str, paste0(saved_boxes[i], "_stack.tif"))
  
  # save the raster for the box
  terra::writeRaster(et_stack, output_name, overwrite = TRUE)
  cat(output_name, "created")

}
```


```{r}
# get global max and min
color_scale <- c(min(terra::global(et_stack,fun="min",na.rm=TRUE)$min),max(terra::global(et_stack,fun="max",na.rm=TRUE)$max))

# make color palette
pal <- colorNumeric(terrain.colors(n = 100),color_scale,na.color = "transparent", reverse = TRUE)

# plot an example of ET
leaflet() %>% 
    addProviderTiles(providers$Esri.WorldImagery) %>%
    addRasterImage(et_stack[[1]], color = pal, opacity = 1) %>%
    addPolygons(data = creekfire_geojson, fill = FALSE) %>%
    addMiniMap(zoomLevelFixed = 10) %>%
    leaflet::addLegend(pal = pal, values = color_scale, title = "ET")

```

```{r, warning=FALSE, message=FALSE}
# look at a fancy map of all the time series
base<-c('map<-leaflet()%>%
            addProviderTiles(providers$Esri.WorldImagery) %>%
            addMiniMap(zoomLevelFixed = 5) %>%')

# make a string including the addRasterImage function for every layer in the raster stack
X <- lapply(1:nlyr(et_stack), function(j){
    paste(paste("addRasterImage(et_stack[[",j,"]],
             colors = pal,
             opacity=1,
             group=names(et_stack[[",j,"]]))", sep=""),"%>% \n")})

X <- do.call(paste, X)

controls<-"addLayersControl(baseGroups=names(et_stack),
               options = layersControlOptions(collapsed=F), position = 'topleft')%>%"

legend <- "leaflet::addLegend(pal = pal, values = color_scale, title = 'ET')"

final <- paste(base, X, controls, legend ,sep="\n")
eval(parse(text=final))
map
```

