---
title: "build_models_rET"
author: "Carrie Hashimoto"
date: "2024-07-29"
output: html_document
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(comment = NA)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

```{r, warning = FALSE, message = FALSE}
packages <- c('tidyverse','mgcv','akima','readr','data.table','vroom',
              'foreach','doParallel','readr','caret','leaps','parallel','leaps',
              'viridis','combinat','coefplot','car','interactions','ggeffects')

# Identify missing (not installed) packages
new.packages <-  packages[!(packages %in% installed.packages()[,"Package"])]

# Install new (not installed) packages
if(length(new.packages)) install.packages(new.packages, repos='http://cran.rstudio.com/') else print('All required packages are installed.')

invisible(lapply(packages, library, character.only = TRUE))
```

```{r}
wd <- rprojroot::find_rstudio_root_file()
outDir <- file.path(wd, "Data", fsep="/")
suppressWarnings(dir.create(outDir)) 

num_cores <- detectCores() - 1
cl <- makeCluster(num_cores - 1)  # Use one less core than available
registerDoParallel(cl)
```

```{r}
df <- vroom::vroom("model_df.csv")
```

```{r}
predictors <- c("prefire_ndvi","dnbr","elev","slope","aspect",
                   "north","lat","temp","precip")
```

```{r}
# start with a basic MLR model
lm_rET <- lm(rET ~ prefire_ndvi + dnbr + elev + slope + aspect + north +
               lat + temp + precip, data = df)

summary.lm_rET <- summary(lm_rET)
summary.lm_rET 

save(lm_rET, file = "lm_rET.RData")
```


```{r}
cor_matrix <- cor(df[predictors], use = "complete.obs")
cor_matrix

# Generate two-way interactions
two_way_interactions <- combn(predictors, 2, function(x) paste(x, collapse = ":"))

# Print two-way interactions
two_way_interactions

# Only grab the ones of interest... otherwise it would take too long :(
all_terms <- c(predictors,two_way_interactions)

# Create the formula
interaction_formula <- as.formula(paste("rET ~", paste(all_terms, collapse = " + ")))

# Print the formula
interaction_formula
```

```{r}
# make a huge interaction model
lm_rET_interaction <- lm(interaction_formula, data = df)

summary.lm_rET_interaction <- summary(lm_rET_interaction)
summary.lm_rET_interaction

save(lm_rET_interaction, file = "lm_rET_interaction.RData")

# so some of these aren't helpful; do model selection
```




```{r}
library(leaps)

set.seed(0)

k <- 10
n <- nrow(df)

folds <- sample(rep(1:k, length = n))

cv.errors <- matrix(NA, k, 10, dimnames = list(NULL, paste(1:10)))

# Define a prediction function for regsubsets models
predict.regsubsets <- function(object, newdata, id) {
  # Extract the formula from the regsubsets object
  formula <- as.formula(object$call[[2]])
  mat <- model.matrix(formula, newdata)
  coefi <- coef(object, id = id)
  xvars <- names(coefi)
  mat[, xvars, drop = FALSE] %*% coefi
}
```


```{r}
# Cross-validation loop
for (j in 1:k) {
  train_data <- df[folds != j, ]
  test_data <- df[folds == j, ]
  
  # Fit the regsubsets model on the training data
  best.fit <- regsubsets(rET ~ prefire_ndvi + dnbr + elev + slope + aspect + north + lat + 
    temp + precip + prefire_ndvi:dnbr + prefire_ndvi:elev + prefire_ndvi:slope + 
    prefire_ndvi:aspect + prefire_ndvi:north + prefire_ndvi:lat + 
    prefire_ndvi:temp + prefire_ndvi:precip + dnbr:elev + dnbr:slope + 
    dnbr:aspect + dnbr:north + dnbr:lat + dnbr:temp + dnbr:precip + 
    elev:slope + elev:aspect + elev:north + elev:lat + elev:temp + 
    elev:precip + slope:aspect + slope:north + slope:lat + slope:temp + 
    slope:precip + aspect:north + aspect:lat + aspect:temp + 
    aspect:precip + north:lat + north:temp + north:precip + lat:temp + 
    lat:precip + temp:precip, data = train_data, nvmax = 10)
  
  for (i in 1:10) {
    pred <- predict.regsubsets(best.fit, newdata = test_data, id = i)
    cv.errors[j, i] <- mean((test_data$aET - pred)^2)
  }
}

# Calculate average CV error for each model size
mean_cv_errors <- apply(cv.errors, 2, mean)

# Print results
print(mean_cv_errors)

```

```{r}
# result: 10x10 matrix where [j,i]th element is test MSE for the jth CV fold for the best i-variable model
cv.errors

mean.cv.errors <- apply(cv.errors, 2, mean)
mean.cv.errors

# plot that shit
plot(mean.cv.errors, type="b")

best_model_size <- which.min(mean.cv.errors)
```

```{r}
# welp
# now try the full model

lm_rET_best_subset <- regsubsets(interaction_formula,
           data=df, nvmax = 10)

lm_rET_best_subset.summary <- summary(lm_rET_best_subset)

lm_rET_best_subset.summary

final_coefs <- coef(lm_rET_best_subset, id = best_model_size) # best model size
print(final_coefs)
```

```{r}
# final model

lm_rET_final <- lm(rET ~ dnbr + lat + precip + prefire_ndvi:dnbr + elev:dnbr +
                     lat:dnbr + lat:precip, data=df)

lm_rET_final.summary <- summary(lm_rET_final)
lm_rET_final.summary
```

Try lasso if time:
```{r}
library(glmnet)

# prep data
response <- df$rET
predictors <- model.matrix(interaction_formula, data = df)[,-1]

# standardize predictors... 10000 deaths
predictors <- scale(predictors)

# Cross-validation to find the best lambda
set.seed(0)
cv_fit <- cv.glmnet(predictors, response, alpha = 1, nfolds = 10)  # alpha = 1 for Lasso, 0 for Ridge

# Get the best lambda
best_lambda <- cv_fit$lambda.min

# Fit the final model with the best lambda
final_model <- glmnet(predictors, response, alpha = 1, lambda = best_lambda)

# Print the coefficients of the final model
print(coef(final_model))

# Plot the cross-validation results
plot(cv_fit)


print("MLR Coefficients:")
print(coef(lm_rET_interaction))

print("Lasso Coefficients:")
print(coef(final_model))


```






```{r}
stopCluster(cl)
registerDoSEQ()
```

